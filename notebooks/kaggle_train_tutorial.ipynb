{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b0483c",
   "metadata": {},
   "source": [
    "# What is this notebook about?\n",
    "Although the datasets used in this project are not that big, do you:\n",
    "- Have a machine that cannot handle loading all the data at once due to limited RAM?\n",
    "- Not have access to your own GPU with CUDA to run training?\n",
    "\n",
    "If this is the case, don't worry! In this notebook, I will show you how to leverage Kaggle's free computing resource to run training!\n",
    "\n",
    "**Prerequisites:**\n",
    "- All you need is a Kaggle account!\n",
    "- And maybe VSCode too if you are planning to edit the\n",
    "    notebook locally while using Kaggle's kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393d248",
   "metadata": {},
   "source": [
    "# Setting Things Up\n",
    "In this section, we will:\n",
    "- Package and upload the necessary source code to Kaggle as a dataset.\n",
    "- Upload the training script as a Utility Script on Kaggle.\n",
    "- Create a notebook to assemble the actual datasets, source code and training script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83220166",
   "metadata": {},
   "source": [
    "## Let's Start Locally\n",
    "As you can see, this project includes quite a lot of pacakged code that can not be copied straight into a notebook to be run on Kaggle. So we must package these code and upload to Kaggle first so we can reference them later on.\n",
    "\n",
    "From your terminal of choice, navigate to the `src` directory:\n",
    "```bash\n",
    "cd src\n",
    "```\n",
    "and execute:\n",
    "```bash\n",
    "zip src.zip . -rx \"*__pycache__/*\"\n",
    "```\n",
    "This will zip everything within the `src` directory (except for the `__pycache__` directories, if there are any).\n",
    "\n",
    "You should see a file named `src.zip` appear in the directory.\n",
    "\n",
    "![src.zip](../assets/kaggle_tutorial/ls_zip.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465fc100",
   "metadata": {},
   "source": [
    "## Uploading The Packaged Code To Kaggle\n",
    "Now, our strategy is to upload the packaged code as a dataset, so we can add it as to `sys.path` for Python to search for later on.\n",
    "\n",
    "It should be straight-forward, create a dataset and upload the zip file.\n",
    "\n",
    "<img src=\"../assets/kaggle_tutorial/new_notebook.png\" width=150>\n",
    "<img src=\"../assets/kaggle_tutorial/create_dataset.png\" width=306>\n",
    "\n",
    "You may have also noticed this is when we should upload our training data as a dataset as well. Just follow the same steps as above, zip everything and upload the zip file.\n",
    "\n",
    "If you intend to use the GTZAN or FMA dataset, then all of the files are already zipped, you just need to upload the zip file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cbbc35",
   "metadata": {},
   "source": [
    "## Creating A Notebook To Host Your Session\n",
    "This is where you will assemble everything together. First, create a new notebook. Then, add the datasets you will use for training, as well as the \"dataset\" leading to the packaged code.\n",
    "\n",
    "<img src=\"../assets//kaggle_tutorial/new_notebook.png\" width=150>\n",
    "<img src=\"../assets//kaggle_tutorial/notebook_view.png\" height=347>\n",
    "\n",
    "In my case, my packaged code is stored in the `genre-classify` dataset. Before moving on, you should also copy the path leading to your packaged code.\n",
    "\n",
    "It should have the format: `/kaggle/input/your-dataset-name`. For example, my path is `/kaggle/input/genre-classify`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76b9955",
   "metadata": {},
   "source": [
    "## Uploading The Training Script To Kaggle\n",
    "As you may have noticed, we have packaged the code and uploaded the training data. However, we have yet touched the main training script `train.py`.\n",
    "\n",
    "Once again, we will create another notebook. However, this time, navigate to `File > Editor Type` and select `Script`. You will see the UI change to a script-like editor view.\n",
    "\n",
    "<img src=\"../assets/kaggle_tutorial/script_editor.png\" height=500>\n",
    "\n",
    "Now, navigate to `train.py`, copy and paste everything in this file to the Kaggle editor. At the second line in the script, replace the old path with your previous path pointing to the dataset where the packaged code is saved.\n",
    "\n",
    "![sys_path](../assets/kaggle_tutorial/sys_path.png)\n",
    "\n",
    "Finally, navigate to `File` item and choose the option `Set as Utility Script`. Now, you can add this as a utility script to your main notebook. You should see the following inputs in your notebook:\n",
    "\n",
    "![final_input](../assets/kaggle_tutorial/final_input.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ba9322",
   "metadata": {},
   "source": [
    "# Running The Code\n",
    "If you have set up everything, you can now run the code in this notebook.\n",
    "\n",
    "You can either:\n",
    "- Upload this notebook to the notebook you have previously created.\n",
    "- Create, run a Kaggle session and connect to the running server.\n",
    "\n",
    "Since the first option is relatively straight-forward, I will show you the second one. Note that you will need VSCode and its Jupyter extension to do this.\n",
    "\n",
    "I also reccommend going with the esecond option as you can have a notebook to edit locally without the hassle of uploading and saving it on Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb19f8ca",
   "metadata": {},
   "source": [
    "## How To Connect To The Running Kaggle Session?\n",
    "Once you have started a session, navigate to `Run` and select `Kaggle Jupyter Server`. You will see a panel pop up on the right hand side.\n",
    "\n",
    "<img src=\"../assets/kaggle_tutorial/kaggle_server.png\" width=400>\n",
    "<img src=\"../assets/kaggle_tutorial/kaggle_server_1.png\" height=410>\n",
    "\n",
    "As you can see, there is a link called `VSCode Compatible URL`. Go ahead and copy this link.\n",
    "\n",
    "In this notebook, click on the `Select Kernel` option and choose `Select Another Kernel... > Existing Jupyter Server...`. Then you will be prompted to enter a URL to connect to the remote server, enter your copied URL.\n",
    "\n",
    "![server](../assets/kaggle_tutorial/jupyter_server.png)\n",
    "\n",
    "After that, proceed as prompted and you will get to choose a kernel to connect to. You are now ready to run the code below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d665439c",
   "metadata": {},
   "source": [
    "#\n",
    "Remember to copy the path to your training script and paste it into the first line of cell number 5.\n",
    "\n",
    "For example, my path is `/kaggle/usr/lib/train_genre_classify/genre_classify_train_script.py`.\n",
    "\n",
    "You may also alter any code as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21513b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are uninstalling the datasets library because it clashes with our packages\n",
    "%pip uninstall -y datasets\n",
    "\n",
    "# These are the required dependencies you need to install before running\n",
    "%pip install -qU tensorflow\n",
    "\n",
    "# This one is optional, you only need this if you intend to use 8-bit optimizers\n",
    "%pip install -q bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d595f8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "import subprocess, itertools, functools, yaml\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57db0052",
   "metadata": {},
   "source": [
    "# Configurations\n",
    "Change your configurations here, it should have the same structure\n",
    "as the `train_config.yml` file.\n",
    "\n",
    "Similarly, specify the model architecture that you want to train in the second\n",
    "cell of this section. It should have the same structure as the `model.yml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e1700",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = {\n",
    "    \"data_args\": {\n",
    "        \"type\": \"fma\",\n",
    "        # \"root\": \"/kaggle/input/gtzan-music\",\n",
    "        \"root\": [\n",
    "            \"/kaggle/input/fma-small/fma_metadata/fma_metadata\",\n",
    "            \"/kaggle/input/fma-small/fma_small/fma_small\"\n",
    "        ],\n",
    "        \"subset_ratio\": .8,\n",
    "        \"sampling_rate\": 22050,\n",
    "        \"seed\": 4,\n",
    "        \"train_ratio\": .8,\n",
    "        \"first_n_secs\": 20,\n",
    "        \"random_crops\": 0,\n",
    "    },\n",
    "    \"inout\": {\n",
    "        \"model_path\": \"model.yml\",\n",
    "        \"logdir\": \"logs\",\n",
    "        \"ckpt_dir\": \"\",\n",
    "        \"checkpoint\": None,\n",
    "    },\n",
    "    \"feature_args\": {\n",
    "        \"feature_type\": \"\",\n",
    "        \"n_mels\": 128,\n",
    "        \"n_mfcc\": 14,\n",
    "        \"n_fft\": 2048,\n",
    "        \"window_type\": \"hann\",\n",
    "    },\n",
    "    \"training_args\": {\n",
    "        \"distributed_training\": False,\n",
    "        \"mixed_precision\": True,\n",
    "        \"epochs\": 100,\n",
    "        \"batch_size\": 32,\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"adamw\",\n",
    "        \"use_8bit_optimizer\": False,\n",
    "        \"kwargs\": {\n",
    "            \"lr\": 1.0e-5,\n",
    "        }\n",
    "    },\n",
    "    \"lr_schedulers\": {\n",
    "        \"warmup\": {\n",
    "            \"total_steps\": 20,\n",
    "            \"start_factor\": 1e-4\n",
    "        },\n",
    "        \"decay\": {\n",
    "            \"type\": 'cosine',\n",
    "            \"kwargs\": {'T_max': 80}\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e028c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"cnn_s\": {\n",
    "        \"backbone\": {\n",
    "            \"type\": \"cnn\",\n",
    "            \"inner_channels\": [\n",
    "                32, 32, 64, 64,\n",
    "                128, 128, 128,\n",
    "                256, 256, 256\n",
    "            ],\n",
    "            \"is_downsampled\": [\n",
    "                0, 1, 0, 1,\n",
    "                0, 0, 1,\n",
    "                0, 0, 1\n",
    "            ],\n",
    "            \"kernel_size\": 3,\n",
    "            \"activation\": \"relu\",\n",
    "            \"pooling_type\": \"max\"\n",
    "        },\n",
    "        \"head\": {\n",
    "            \"hidden_dims\": [512],\n",
    "            \"dropout_probs\": [.2],\n",
    "            \"activation\": \"relu\"\n",
    "        }\n",
    "    },\n",
    "    \"cnn_m\": {\n",
    "        \"backbone\": {\n",
    "            \"type\": \"cnn\",\n",
    "            \"inner_channels\": [\n",
    "                64, 64,\n",
    "                128, 128, 128,\n",
    "                256, 256, 256,\n",
    "                512, 512, 512\n",
    "            ],\n",
    "            \"is_downsampled\": [\n",
    "                0, 1,\n",
    "                0, 0, 1,\n",
    "                0, 0, 1,\n",
    "                0, 0, 1\n",
    "            ],\n",
    "            \"kernel_size\": 3,\n",
    "            \"activation\": \"relu\",\n",
    "            \"pooling_type\": \"max\"\n",
    "        },\n",
    "        \"head\": {\n",
    "            \"hidden_dims\": [1024, 1024],\n",
    "            \"dropout_probs\": [.2, .2],\n",
    "            \"activation\": \"relu\"\n",
    "        }\n",
    "    },\n",
    "    \"resnet\": {\n",
    "        \"backbone\": {\n",
    "            \"type\": \"resnet\",\n",
    "            \"inner_channels\": [\n",
    "                128, 128, 128,\n",
    "                256, 256, 256,\n",
    "                512, 512, 512,\n",
    "            ],\n",
    "            \"is_downsampled\": [\n",
    "                0, 0, 0,\n",
    "                1, 0, 0,\n",
    "                1, 0, 0,\n",
    "            ],\n",
    "            \"kernel_size\": 3,\n",
    "            \"activation\": \"relu\",\n",
    "            \"pooling_type\": \"max\"\n",
    "        },\n",
    "        \"head\": {\n",
    "            \"hidden_dims\": [1024, 1024],\n",
    "            \"dropout_probs\": [.2, .2],\n",
    "            \"activation\": \"relu\"\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9fb61",
   "metadata": {},
   "source": [
    "# Calling Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4714567",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script = \"/kaggle/usr/lib/train_genre_classify/genre_classify_train_script.py\"\n",
    "\n",
    "def run(\n",
    "    features, lrs, wcs,\n",
    "    model_name, ckpt_root, default_config,\n",
    "    *,\n",
    "    num_workers=4\n",
    "):\n",
    "    pbar = tqdm(\n",
    "        itertools.product(features, lrs, wcs), desc='Conf',\n",
    "        total=functools.reduce(\n",
    "            lambda x, y: x * y, map(len, [features, lrs, wcs])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for feature, lr, weight_decay in pbar:\n",
    "        default_config['feature_args']['feature_type'] = feature\n",
    "        default_config['optimizer']['kwargs']['lr'] = lr\n",
    "        default_config['optimizer']['kwargs']['weight_decay'] = weight_decay\n",
    "\n",
    "        weight_decay = f\"{weight_decay:.0e}\" if weight_decay != 0 else 0\n",
    "        if feature == 'mel':\n",
    "            feature += f\"-{default_config['feature_args']['n_mels']}\"\n",
    "        elif feature == 'mfcc':\n",
    "            feature += f\"-{default_config['feature_args']['n_mfcc']}\"\n",
    "        default_config['inout']['ckpt_dir'] = (\n",
    "            f\"{ckpt_root}/{feature}/{model_name}_{lr:.0e}_{weight_decay}\"\n",
    "        )\n",
    "        with open('train_config.yml', 'w', encoding='utf-8') as file:\n",
    "            yaml.safe_dump(default_config, file, sort_keys=False)\n",
    "\n",
    "        pbar.set_postfix_str(f\"{model_name}, {feature}, {lr=}, {weight_decay=}\")\n",
    "        print()\n",
    "        subprocess.call([\"python\", train_script, \"-nw\", f\"{num_workers}\", \"-d\", \"cuda:0\"])\n",
    "        clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb69c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_root = 'checkpoints'\n",
    "\n",
    "run_names = ['cnn_s', 'cnn_m']\n",
    "epochs = {'cnn': 100, 'resnet': 300}\n",
    "for name, model in models.items():\n",
    "    if run_names and not name in run_names: continue\n",
    "\n",
    "    with open('model.yml', 'w', encoding='utf-8') as file:\n",
    "        yaml.safe_dump(model, file, sort_keys=False)\n",
    "\n",
    "    epoch = epochs[model['backbone']['type']]\n",
    "    default_config['training_args']['epochs'] = epoch\n",
    "    if default_config['lr_schedulers']['decay']['type'] == 'cosine':\n",
    "        default_config['lr_schedulers']['decay']['kwargs']['T_max'] = (\n",
    "            epoch - default_config['lr_schedulers']['warmup']['total_steps']\n",
    "        )\n",
    "\n",
    "    run(\n",
    "        ['midi'],\n",
    "        [1e-5],\n",
    "        [.01],\n",
    "        name, 'checkpoints', default_config,\n",
    "        num_workers=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca3a5d6",
   "metadata": {},
   "source": [
    "You can download all of your checkpoints by zipping it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9da2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -FS -r ckpt_no_pth.zip checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c029c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r checkpoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".genre_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
