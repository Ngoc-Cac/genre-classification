data_args:
  root: path_to_dataset
  seed: 4
  train_ratio: .8
  first_n_secs: 20
  random_crops: 0

feature_args:
  feature_type: midi
  n_mels: 128
  n_fft: 2048
  window_type: hann

training_args:
  epochs: 100
  batch_size: 32
  learning_rate: 1.0e-5
  regularization_lambda: 0
  optimizer: adam
  use_8bit_optimizer: false
  distributed_training: false
  mixed_precision: false

inout:
  logdir: logs
  ckpt_dir: your_checkpoint_dir
  checkpoint: latest

model:
  backbone: cnn
  inner_channels: [64, 64, 64, 128, 128, 128, 256, 256, 256]
  downsampling_rates: [2, 1, 1, 2, 1, 1, 2, 1, 1]
  num_linear_layers: 0

### Description of parameters ###
#################################
# data_args:
#   root: path to the data
#   seed: seed for splitting data
#   train_ratio: The train-test split ratio
#   first_n_secs: Whether to use only the first_n_secs of audio.
#     Sepcify -1 to use all of the audio. You must make sure all audio have
#     the same amount of samples
#   random_crops: How many random crops to create from one audio file in the dataset.
#     This acts as an augmentation of the dataset, where each crop is a first_n_secs-
#     second-long segment of the original audio, starting at a random position.
#     This will only take effect if first_n_secs != -1.
# feature_args:
#   feature_type: Type of feature for spectrogram, choose between chroma, midi and mfcc
#   n_mels: The number of mel filterbanks. This is only use when feature_type is 'mfcc'
#   n_fft: The number of samples to perform FFT in STFT
#   window_type: The type of window used in STFT. Currently, only hann is available
# training_args:
#   epochs: Total number of training epochs
#   batch_size: self-explanatory
#   learning_rate: see above
#   regularization_lambda: The lambda for L2 regularization, leave 0 for no regularization
#   optimizer: Choose between adam, adamw and sgd
#   use_8bit_optimizer: Whether or not to use 8bit-optimization
#   distributed_training: Whether or not to run distributed training. Only available
#     if multiple GPUs are present.
#   mixed_precision: Whether or not to run mixed precision training with fp16.
# inout:
#   logdir: A directory with this name will be created in ckpt_dir
#   ckpt_dir: Where the models should be checkpointed
#   checkpoint: Previous checkpoint of the model. Specify latest to load latest checkpoint
# model:
#   backbone: The backbone used for feature extraction, choose between cnn and resnet
#   inner_channels: The desired channel dimension after each layer in the backbone.
#     For example, [8, 16, 32] specifies that the feature map produced by the first
#     layer of the backbone is 8, second layer is 16, etc. 
#   downsampling_rates: The downsampling rate at each layer in the backbone.
#     For example, [2, 1, 1] specifies that the feature map produced by the first
#     layer of the backbone will be downsampled by 2 in its spatial dimension. For
#     the layers afterward, the spatial dimension of the output feature map stays
#     constant.
#   num_linear_layers: The number of hidden linear layers used for classification.
#     These are the layers that take in the final feature map output by the backbone
#     before passing it the final output layer for predicting the output logits.
#################################